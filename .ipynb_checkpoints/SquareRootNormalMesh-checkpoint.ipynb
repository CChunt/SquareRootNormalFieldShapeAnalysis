{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7aca2b6-f1dd-430b-8a93-64d2d6dfef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyvista\n",
    "#!pip install pyvista[jupyter]\n",
    "#!pip install pyvistaqt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pyvista as pv\n",
    "from pyvistaqt import BackgroundPlotter\n",
    "import time as time\n",
    "from skimage.measure import marching_cubes\n",
    "import nibabel as nib\n",
    "from nibabel.processing import resample_from_to\n",
    "import imageio\n",
    "import pickle\n",
    "from scipy.optimize import brentq\n",
    "pv.set_jupyter_backend('none')    # if you want the trame-based UI\n",
    "\n",
    "def print_data(mesh):\n",
    "    print(mesh.point_data)\n",
    "    print(mesh.cell_data)\n",
    "    print(mesh.field_data)\n",
    "\n",
    "def load_pickle(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def save_pickle(obj, path):\n",
    "    path = Path(path)\n",
    "    tmp = path.with_suffix(path.suffix + \".tmp\")\n",
    "    with open(tmp, \"wb\") as f:\n",
    "        pickle.dump(obj, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    os.replace(tmp, path)  # atomic replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b559dc-7384-487c-b506-b23e05315427",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "import numpy as np, pyvista as pv, uuid\n",
    "\n",
    "def make_edge_dict(mesh):\n",
    "    \"\"\"\n",
    "    Extract edge data from a mesh from vertex and face lists.\n",
    "    Returns a dictionary with each edge as a key in the form\n",
    "    of a sorted tuple, [(v0, v1)] if v0 < v1, [(v1, v0)] if v1 < v0.\n",
    "    Each key/edge will contain another dictionary with keys:\n",
    "    [opposite_vertex_0 : int, opposite_vertex_1 : int, \n",
    "     weight (w = cot(opposite_angle_0) + cot(opposite_angle_1)) : float]\n",
    "\n",
    "     Parameters\n",
    "     ----------\n",
    "     mesh : pv.PolyData\n",
    "     \n",
    "     Returns\n",
    "     -------\n",
    "     edge_dict : dictionary\n",
    "         Contains a dict for each edge [(v0,v1)] with keys opposite_vertex_0,\n",
    "         opposite_vertex_1, and weight. opposite_vertex_i contains\n",
    "         float of the angle in radians made by the three vertices\n",
    "         v0, opposite_vertex_i, v1\n",
    "    \"\"\"\n",
    "    verts = mesh.points\n",
    "    faces = mesh.faces\n",
    "    edge_dict = {}\n",
    "    if faces.ndim == 1:\n",
    "        faces = faces.reshape(-1, 4)\n",
    "    \n",
    "    for tri in faces[:,1:]:\n",
    "        i, j, k = map(int, tri)\n",
    "        for (a,b,c) in [(i,j,k),(j,k,i),(k,i,j)]:\n",
    "            e = tuple(sorted((a,b)))   # e.g. (min(a,b),max(a,b))\n",
    "            if e not in edge_dict:\n",
    "                edge_dict[e] = {}\n",
    "            v0 = verts[a]\n",
    "            v1 = verts[b]\n",
    "            v2 = verts[c]\n",
    "            e0 = v0 - v2\n",
    "            e1 = v1 - v2\n",
    "            costheta = np.dot(e0, e1) / (np.linalg.norm(e0) * np.linalg.norm(e1) + 1e-15)\n",
    "            costheta = np.clip(costheta, -1, 1)\n",
    "            angle = np.arccos(costheta)\n",
    "            edge_dict[e][c] = float(angle)     # store the vertex “across” this edge\n",
    "            if len(edge_dict[e]) == 2:\n",
    "                angle0 = list(edge_dict[e].items())[0][1]\n",
    "                w = (np.cos(angle0)/(np.sin(angle0) + 1e-15)) + (np.cos(angle)/(np.sin(angle) + 1e-15))\n",
    "                edge_dict[e]['weight'] = float(w)\n",
    "    edges_idx = np.array([(i[0], i[1]) for i in edge_dict], dtype=int)\n",
    "    weights = np.array([edge_dict[i].get('weight', 0.0) for i in edge_dict], dtype=float)\n",
    "\n",
    "    return edge_dict, edges_idx, weights\n",
    "\n",
    "def string_energy_vec(edges_idx, weights, phi):\n",
    "    # # phi: (N,3) array of vertex coords on the sphere\n",
    "    # phi = mesh['spherical_param']\n",
    "    # edges_idx = mesh['edges_idx']\n",
    "    # weights = mesh['edges_weights']\n",
    "    i0 = edges_idx[:,0]\n",
    "    i1 = edges_idx[:,1]\n",
    "    # shape (E,3) differences\n",
    "    diffs = phi[i0] - phi[i1]\n",
    "    # squared‐norm per edge, shape (E,)\n",
    "    sqnorm = np.einsum('ij,ij->i', diffs, diffs)\n",
    "    # sum w * sqnorm\n",
    "    return float(np.dot(weights, sqnorm))\n",
    "\n",
    "def extract_vertex_face_energies(\n",
    "    verts_sph: np.ndarray,\n",
    "    faces_pv: np.ndarray,\n",
    "    edges_idx: np.ndarray,\n",
    "    weights: np.ndarray,\n",
    "    *,\n",
    "    return_means: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute discrete Dirichlet energy contributions of a spherical parameterization.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    eE : (E,) per-edge energy w_ij * ||phi_i - phi_j||^2\n",
    "    fE : (F,) per-face sum of incident edge energies (split equally among incident faces)\n",
    "    vE : (V,) per-vertex sum of incident edge energies (split 0.5 to each endpoint)\n",
    "    (optionally) fE_mean, vE_mean : means normalized by incidence counts\n",
    "    \"\"\"\n",
    "    # faces as (F,3)\n",
    "    faces = faces_pv.reshape(-1, 4)[:, 1:] if faces_pv.ndim == 1 else faces_pv\n",
    "    V = verts_sph.shape[0]\n",
    "    F = faces.shape[0]\n",
    "    E = edges_idx.shape[0]\n",
    "\n",
    "    # 1) per-edge energy\n",
    "    i0, i1 = edges_idx[:, 0], edges_idx[:, 1]\n",
    "    diffs = verts_sph[i0] - verts_sph[i1]               # (E,3)\n",
    "    len2  = np.einsum('ij,ij->i', diffs, diffs)         # (E,)\n",
    "    eE    = weights * len2                               # (E,)\n",
    "\n",
    "    # 2) per-vertex accumulation (split evenly to endpoints)\n",
    "    vE = np.zeros(V, dtype=float)\n",
    "    np.add.at(vE, i0, 0.5 * eE)\n",
    "    np.add.at(vE, i1, 0.5 * eE)\n",
    "\n",
    "    # 3) per-face accumulation\n",
    "    # Build a light vertex->faces adjacency to find faces adjacent to each edge\n",
    "    v2f = [[] for _ in range(V)]\n",
    "    for fi, (a, b, c) in enumerate(faces):\n",
    "        v2f[a].append(fi); v2f[b].append(fi); v2f[c].append(fi)\n",
    "\n",
    "    fE = np.zeros(F, dtype=float)\n",
    "    face_inc_counts = np.zeros(F, dtype=int)\n",
    "\n",
    "    for k, (a, b) in enumerate(edges_idx):\n",
    "        adj = list(set(v2f[a]) & set(v2f[b]))  # 1 (boundary) or 2 (interior)\n",
    "        if len(adj) == 0:\n",
    "            # Non-manifold or disconnected edge; skip or assign nowhere\n",
    "            continue\n",
    "        share = eE[k] / len(adj)\n",
    "        for fi in adj:\n",
    "            fE[fi] += share\n",
    "            face_inc_counts[fi] += 1\n",
    "\n",
    "    if not return_means:\n",
    "        return eE, fE, vE\n",
    "\n",
    "    # 4) Optional: means normalized by incidence (avoid division by zero)\n",
    "    # For vertices, count how many incident edges per vertex\n",
    "    vertex_inc_counts = np.zeros(V, dtype=int)\n",
    "    np.add.at(vertex_inc_counts, i0, 1)\n",
    "    np.add.at(vertex_inc_counts, i1, 1)\n",
    "\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        vE_mean = np.where(vertex_inc_counts > 0, vE / vertex_inc_counts, 0.0)\n",
    "        fE_mean = np.where(face_inc_counts   > 0, fE / face_inc_counts,     0.0)\n",
    "\n",
    "    return eE, fE_mean, vE_mean\n",
    "\n",
    "\n",
    "def d_energy_vec(edges_idx, weights, phi):\n",
    "    \"\"\"\n",
    "    Vectorized ∂E/∂Phi for all vertices at once.\n",
    "    \n",
    "    edges_idx : (E,2) int array of [i,j] pairs\n",
    "    weights   : (E,)  float array of w_ij\n",
    "    phi       : (N,3) float array of Phi positions\n",
    "\n",
    "    returns grad : (N,3) float array of 2*sum_j w_ij*(Phi_i - Phi_j)\n",
    "    \"\"\"\n",
    "    i0 = edges_idx[:, 0]      # shape = (E,)\n",
    "    i1 = edges_idx[:, 1]      # shape = (E,)\n",
    "\n",
    "    # 1) compute the per-edge vector differences\n",
    "    diffs    = phi[i0] - phi[i1]         # (E,3)\n",
    "\n",
    "    # 2) weight them\n",
    "    w_diffs  = diffs * weights[:, None]  # (E,3)\n",
    "\n",
    "    # 3) scatter‐add into a per-vertex accumulator\n",
    "    grad     = np.zeros_like(phi)        # (N,3)\n",
    "    np.add.at(grad, i0,  w_diffs)        # grad[i0] +=  w_diffs\n",
    "    np.add.at(grad, i1, -w_diffs)        # grad[i1] -=  w_diffs\n",
    "\n",
    "    # 4) if you want the true energy‐gradient, multiply by 2\n",
    "    # grad *= 2\n",
    "\n",
    "    return grad\n",
    "\n",
    "def C2_adaptive(phi0, edges_idx, weights, *,\n",
    "                tol=1e-10, max_iter=10_000, initial_dt=0.1):\n",
    "    \"\"\"\n",
    "    Projected gradient descent on S^2 to minimize sum w_ij ||phi_i - phi_j||^2.\n",
    "    Inputs:\n",
    "      phi0: (N,3) initial directions (will be normalized)\n",
    "      edges_idx: (E,2) int\n",
    "      weights: (E,) float\n",
    "    Returns:\n",
    "      phi: (N,3) final S^2 embedding\n",
    "      energies: list of energy values over iterations\n",
    "    \"\"\"\n",
    "    # normalize just in case\n",
    "    phi = phi0 / (np.linalg.norm(phi0, axis=1, keepdims=True) + 1e-15)\n",
    "\n",
    "    E = string_energy_vec(edges_idx, weights, phi)\n",
    "    energies = [E]\n",
    "    dt = float(initial_dt)\n",
    "\n",
    "    for it in range(1, max_iter+1):\n",
    "        g = d_energy_vec(edges_idx, weights, phi)\n",
    "        # project gradient onto tangent space\n",
    "        g_proj = g - (np.einsum('ij,ij->i', g, phi))[:, None] * phi\n",
    "\n",
    "        ok = False\n",
    "        dt_try = dt\n",
    "        for _ in range(6):\n",
    "            phi_try = phi - dt_try * g_proj\n",
    "            phi_try /= (np.linalg.norm(phi_try, axis=1, keepdims=True) + 1e-15)\n",
    "            E_try = string_energy_vec(edges_idx, weights, phi_try)\n",
    "            if E_try < E:\n",
    "                phi, E = phi_try, E_try\n",
    "                energies.append(E)\n",
    "                dt = min(dt_try * 1.25, 1.0)\n",
    "                ok = True\n",
    "                break\n",
    "            dt_try *= 0.25\n",
    "\n",
    "        if not ok or (energies[-2] - energies[-1]) < tol:\n",
    "            break\n",
    "\n",
    "    return phi, energies\n",
    "\n",
    "\n",
    "def srnf_from_mesh(mesh):\n",
    "    mesh.compute_normals(point_normals=False, cell_normals=True, inplace=True)\n",
    "    mesh['Area'] = mesh.compute_cell_sizes(length=False, area=True, volume=False)['Area']\n",
    "    u = mesh.cell_data[\"Normals\"]                # (F, 3)\n",
    "    A = mesh.cell_data[\"Area\"]                  # (F,)\n",
    "    q = u * np.sqrt(2.0 * A)[:, None]           # (F, 3)\n",
    "    return q\n",
    "\n",
    "def get_icosphere_level(A, B, nsub):\n",
    "    if nsub in A.icosphere:\n",
    "        return A.icosphere[nsub]['points'], A.icosphere[nsub]['weights']\n",
    "    if nsub in B.icosphere:\n",
    "        return B.icosphere[nsub]['points'], B.icosphere[nsub]['weights']\n",
    "    U, w = icosphere_quadrature(nsub)  # (M,3), (M,)\n",
    "    A.icosphere[nsub] = {'points': U, 'weights': w}\n",
    "    B.icosphere[nsub] = {'points': U, 'weights': w}\n",
    "    return U, w\n",
    "\n",
    "def l2_q(qA, qB, w):\n",
    "    d = qA - qB\n",
    "    return float(np.dot(w, np.einsum('ij,ij->i', d, d)))\n",
    "\n",
    "# ... keep your helpers as provided above ...\n",
    "def l2(A: \"SquareRootNormalMesh\", B: \"SquareRootNormalMesh\", nsub = 5):\n",
    "    sample_points, sample_weights = get_icosphere_level(A, B, nsub)\n",
    "    if B.uid not in A.alignments.keys():\n",
    "        A.get_alignment(B)\n",
    "    mobius_parameters = A.alignments[B.uid]['mobius_params']\n",
    "    R = A.alignments[B.uid]['space_rotation']\n",
    "    sample_reparam, sqrtJ = mobius_apply_on_sphere(sample_points, mobius_parameters)\n",
    "\n",
    "    q1 = A.sample(sample_points)\n",
    "    gamma_q2 = B.sample(sample_reparam)\n",
    "    R_gamma_q2 = (gamma_q2 @ R.T) * sqrtJ[:, None]\n",
    "    \n",
    "    l2_sq = l2_q(q1, R_gamma_q2, sample_weights)\n",
    "\n",
    "    return l2_sq\n",
    "\n",
    "def stereographic_project(P):  # P: (N,3) unit vectors\n",
    "    X, Y, Z = P[:,0], P[:,1], P[:,2]\n",
    "    denom = 1.0 - Z\n",
    "    # guard near north pole: denom -> 0 => z -> ∞\n",
    "    denom = np.where(np.abs(denom) < 1e-15, 1e-15, denom)\n",
    "    return (X + 1j*Y) / denom  # complex array (N,)\n",
    "\n",
    "def stereographic_unproject(w):  # w: (N,) complex -> (N,3) unit vectors\n",
    "    x = np.real(w); y = np.imag(w)\n",
    "    r2 = x*x + y*y\n",
    "    denom = 1.0 + r2\n",
    "    P = np.stack([2*x/denom, 2*y/denom, (r2 - 1.0)/denom], axis=1)\n",
    "    # numeric safety\n",
    "    P /= np.linalg.norm(P, axis=1, keepdims=True)\n",
    "    return P\n",
    "\n",
    "def mobius_apply_on_sphere(P, mobius_params):\n",
    "    \"\"\"\n",
    "    P: (M,3) unit sphere points\n",
    "    returns: P_gamma (M,3), sqrtJ (M,)\n",
    "    \"\"\"\n",
    "    a, b, c, d = mobius_params\n",
    "    z = stereographic_project(P)            # (M,) complex\n",
    "    czd = c*z + d\n",
    "    w = (a*z + b) / (czd)               # (M,) complex\n",
    "    P_gamma = stereographic_unproject(w)    # (M,3)\n",
    "\n",
    "    # sqrt(J) on the sphere (see derivation in the message)\n",
    "    num = 1.0 + (z.real**2 + z.imag**2)\n",
    "    den = 1.0 + (w.real**2 + w.imag**2)\n",
    "    den2 = np.maximum(np.abs(czd)**2, 1e-15)\n",
    "    sqrtJ = (num/den) / den2      # (M,)\n",
    "    return P_gamma, sqrtJ\n",
    "    \n",
    "def compute_alignment(A: \"SquareRootNormalMesh\", B: \"SquareRootNormalMesh\", nsub = 5):\n",
    "    \"\"\"\n",
    "    q1_sampler, q2_sampler: callables U->q(U)\n",
    "    C:   (M,3) fixed base quadrature points on S²\n",
    "    A:   (M,)  fixed area weights\n",
    "    mobius_params: (tx, ty, s)  # KAN: translate+scale in plane; rotation lives in R_dom\n",
    "    R_dom: optional (3,3) domain rotation (SO(3))\n",
    "    returns: (L2_sq, R_space)\n",
    "    \"\"\"\n",
    "    sample_points, sample_weights = get_icosphere_level(A, B, nsub)\n",
    "    def kabsch_rotation_srnf(Q1, Q2, weights=None, proper_rotation = True):\n",
    "        # Q1,Q2 shape (N,3); each row is a vector; rows correspond\n",
    "        if weights is None:\n",
    "            w = np.ones(len(Q1))\n",
    "        else:\n",
    "            w = np.asarray(weights, float)\n",
    "        w = w / w.sum()            # normalization doesn't change R, just scales Σ\n",
    "    \n",
    "        C = Q1.T @ (Q2 * w[:, None])        # 3x3\n",
    "        U, S, Vt = np.linalg.svd(C, full_matrices=False)\n",
    "        R = U @ Vt                           # = U V^T\n",
    "        if proper_rotation and np.linalg.det(R) < 0:  # reflection fix\n",
    "            U[:, -1] *= -1\n",
    "            R = U @ Vt\n",
    "        return R\n",
    "        \n",
    "    def sample_unit_quat():\n",
    "        # Method B: 3 uniforms → unit quaternion (uniform on SO(3))\n",
    "        u1, u2, u3 = np.random.rand(3)\n",
    "        theta1 = 2*np.pi*u2\n",
    "        theta2 = 2*np.pi*u3\n",
    "        r1 = np.sqrt(1 - u1)\n",
    "        r2 = np.sqrt(u1)\n",
    "        w = r2*np.cos(theta2)\n",
    "        x = r1*np.sin(theta1)\n",
    "        y = r1*np.cos(theta1)\n",
    "        z = r2*np.sin(theta2)\n",
    "        return w, x, y, z\n",
    "    \n",
    "    def su2_from_quat(w, x, y, z):\n",
    "        alpha = w + 1j*z\n",
    "        beta  = y + 1j*x\n",
    "        s = np.sqrt((alpha*alpha.conjugate()).real + (beta*beta.conjugate()).real)\n",
    "        alpha /= s; beta /= s\n",
    "        return np.array([[alpha, beta],\n",
    "                         [-beta.conjugate(), alpha.conjugate()]], dtype=np.complex128)\n",
    "    \n",
    "    def sample_similarity_params(smin=-1.0, smax=1.0, T=1.5):\n",
    "        s = np.random.uniform(smin, smax)          # log-scale\n",
    "        theta = np.random.uniform(0.0, 2*np.pi)    # in-plane spin\n",
    "        u = np.random.uniform(0.0, 1.0)\n",
    "        phi = np.random.uniform(0.0, 2*np.pi)\n",
    "        r = np.sqrt(u)*T                            # translation radius\n",
    "        t = r * np.exp(1j*phi)                      # complex translation\n",
    "        lam = np.exp(s + 1j*theta)                  # complex scale+spin\n",
    "        return lam, t\n",
    "    \n",
    "    def sample_mobius_matrix():\n",
    "        # 1) domain rotation\n",
    "        w,x,y,z = sample_unit_quat()\n",
    "        Mrot = su2_from_quat(w,x,y,z)  # [[α, β], [-β*, α*]]\n",
    "    \n",
    "        # 2) plane similarity\n",
    "        lam, t = sample_similarity_params()\n",
    "        Msim = np.array([[lam, lam*t],\n",
    "                         [0+0j, 1+0j]], dtype=np.complex128)\n",
    "    \n",
    "        # 3) compose: rotate sphere, then plane similarity\n",
    "        M = Msim @ Mrot\n",
    "    \n",
    "        # 4) optional normalization (det = 1)\n",
    "        det = M[0,0]*M[1,1] - M[0,1]*M[1,0]\n",
    "        if np.abs(det) > 1e-15:\n",
    "            M /= np.sqrt(det)\n",
    "    \n",
    "        a, b = M[0,0], M[0,1]\n",
    "        c, d = M[1,0], M[1,1]\n",
    "        return a, b, c, d\n",
    "\n",
    "    best_l2 = 1e10\n",
    "    best_mobius = np.zeros(4)\n",
    "    best_space_rotation = np.zeros((3,3))\n",
    "    for i in range(n):\n",
    "        mobius_params = sample_mobius_matrix()\n",
    "        sample_points_trans, sqrtJ = mobius_apply_on_sphere(sample_points, mobius_params)\n",
    "        q1 = A.sample(sample_points)\n",
    "        gamma_q2 = B.sample(sample_points_trans) * sqrtJ[:, None]\n",
    "        R = kabsch_rotation_srnf(q1, gamma_q2, sample_weights)\n",
    "        R_gamma_q2 = (gamma_q2 @ R.T)\n",
    "\n",
    "        l2_sq = l2_q(q1, R_gamma_q2, sample_weights)\n",
    "        if l2_sq < best_l2:\n",
    "            best_l2 = l2_sq\n",
    "            best_mobius = mobius_params\n",
    "            best_space_rotation = R\n",
    "    return best_mobius, best_space_rotation, best_l2\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SquareRootNormalMesh:\n",
    "    verts: np.ndarray\n",
    "    verts_sph: np.ndarray\n",
    "    faces_pv:  np.ndarray\n",
    "    q_face:    np.ndarray\n",
    "    name: str = \"\"\n",
    "    uid:  str = field(default_factory=lambda: uuid.uuid4().hex)\n",
    "\n",
    "    mesh_sph: pv.PolyData = field(init=False, repr=False)\n",
    "\n",
    "    edge_dict: dict = field(init=False, repr=False)\n",
    "    edge_array: np.ndarray = field(init=False, repr=False)\n",
    "    edge_weights: np.ndarray = field(init=False, repr=False)\n",
    "\n",
    "    sphere_param_edge_energy: np.ndarray = field(init=False, repr=False)\n",
    "    sphere_param_face_energy_mean: np.ndarray = field(init=False, repr=False)\n",
    "    sphere_param_vertex_energy_mean: np.ndarray = field(init=False, repr=False)\n",
    "    sphere_param_log: list = field(default_factory=list)\n",
    "    icosphere: dict = field(default_factory=dict)\n",
    "    alignments: dict = field(default_factory=dict)\n",
    "    pairwise_l2: dict = field(default_factory=dict)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.mesh_sph = pv.PolyData(self.verts_sph, self.faces_pv)\n",
    "\n",
    "    @classmethod\n",
    "    def from_polydata(cls, pv_mesh: pv.PolyData, *, max_iter=5000, name=\"\"):\n",
    "        # build edges/weights\n",
    "        edge_dict, edge_array, edge_weight = make_edge_dict(pv_mesh)\n",
    "\n",
    "        # ensure point normals exist and normalize as φ0 ∈ S²\n",
    "        m = pv_mesh.copy()\n",
    "        m.compute_normals(point_normals=True, cell_normals=False, inplace=True)\n",
    "        phi0 = m.point_normals\n",
    "        phi0 = phi0 / (np.linalg.norm(phi0, axis=1, keepdims=True) + 1e-15)\n",
    "\n",
    "        # optimize on S²\n",
    "        verts_sph, logE = C2_adaptive(phi0, edge_array, edge_weight, max_iter=max_iter)\n",
    "\n",
    "        faces_pv = pv_mesh.faces\n",
    "        q_face = srnf_from_mesh(pv_mesh)\n",
    "\n",
    "        # construct\n",
    "        obj = cls(\n",
    "            verts=pv_mesh.points.copy(),\n",
    "            verts_sph=verts_sph,\n",
    "            faces_pv=faces_pv.copy(),\n",
    "            q_face=q_face,\n",
    "            name=name\n",
    "        )\n",
    "        obj.edge_dict = edge_dict\n",
    "        obj.edge_array = edge_array\n",
    "        obj.edge_weights = edge_weight\n",
    "        obj.mesh_sph = pv.PolyData(verts_sph, faces_pv)\n",
    "\n",
    "        # energies (NOTE: your function aggregates weights, not energy)\n",
    "        eE, fE, vE = extract_vertex_face_energies(verts_sph, faces_pv, edge_array, edge_weight)\n",
    "        obj.sphere_param_edge_energy = eE\n",
    "        obj.sphere_param_face_energy_mean = fE\n",
    "        obj.sphere_param_vertex_energy_mean = vE\n",
    "        obj.sphere_param_log = logE\n",
    "        return obj\n",
    "\n",
    "    @classmethod\n",
    "    def from_voxels(cls, vox: np.ndarray, *, iso=0.5, spacing=(1,1,1), smoothing=None, **kw):\n",
    "        from skimage.measure import marching_cubes\n",
    "        v,f,_,_ = marching_cubes(vox, level=iso, spacing=spacing)\n",
    "        faces_pv = np.c_[np.full((len(f),1),3,np.int32), f.astype(np.int32)].ravel()\n",
    "        pv_mesh = pv.PolyData(v, faces_pv)\n",
    "        if smoothing: pv_mesh = pv_mesh.smooth(n_iter=smoothing)\n",
    "        return cls.from_polydata(pv_mesh, **kw)\n",
    "\n",
    "    def sample(self, U: np.ndarray) -> np.ndarray:\n",
    "        idx = self.mesh_sph.find_closest_cell(U)\n",
    "        return self.q_face[idx]\n",
    "\n",
    "    def preindex(self, U: np.ndarray) -> np.ndarray:\n",
    "        return self.mesh_sph.find_closest_cell(U)\n",
    "\n",
    "    def gather(self, idx: np.ndarray) -> np.ndarray:\n",
    "        return self.q_face[idx]\n",
    "\n",
    "    def get_alignment(self, B: \"SquareRootNormalMesh\", nsub: int = 5) -> None:\n",
    "        output = compute_alignment(self, B, nsub)\n",
    "        self.alignments[B.uid] = {'mobius_params': output[0], 'space_rotation': output[1]}\n",
    "        self.pairwise_l2[B.uid] = output[2]\n",
    "        B.pairwise_l2[self.uid] = output[2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
